# -*- coding: utf-8 -*-
"""chicken.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/180zoLErhKb9QzOpXbdbRL23ApCRaDMH7
"""

#from google.colab import drive

#drive.mount('/content/drive')

from tensorflow.keras.callbacks import ReduceLROnPlateau
import tensorflow
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os
from PIL import Image, UnidentifiedImageError
import numpy as np
import secrets
import os
import matplotlib.pyplot as plt
import matplotlib.image as mpimg
from PIL import Image,ImageFilter

parent_path = r"C:\Users\pc\OneDrive\Documents\chicken"

healthy_path = os.path.join(os.path.join(parent_path, 'data_folder'), 'healthy')
infected_path = os.path.join(os.path.join(parent_path, 'data_folder'), 'infected')

# Visualize a healthy sample image
healthy_sample_path = os.path.join(healthy_path, os.listdir(healthy_path)[0])
healthy_sample_img = mpimg.imread(healthy_sample_path)

# Visualize an infected sample image
infected_sample_path = os.path.join(infected_path, os.listdir(infected_path)[0])
infected_sample_img = mpimg.imread(infected_sample_path)

# Plot side by side
plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.imshow(healthy_sample_img)
plt.title('Healthy Sample')
plt.axis('off')

plt.subplot(1, 2, 2)
plt.imshow(infected_sample_img)
plt.title('Infected Sample')
plt.axis('off')

plt.show()

#include file paths


parent_path1 = os.path.join(parent_path,'data_folder')
path = os.path.join(os.path.join(parent_path, 'data_folder'),'healthy')
path1 = os.path.join(os.path.join(parent_path, 'data_folder'),'infected')
model_path = os.path.join(os.path.join(parent_path, 'chicken_model'),'chicken_predictor.h5')
test_data = os.path.join(parent_path, 'test_data')

#Image Processing
def filter_img(scaled_img):
    boxblurred_img_5 = scaled_img.filter(ImageFilter.BoxBlur(5))
    boxblurred_img_20 = scaled_img.filter(ImageFilter.BoxBlur(20))
    gaussianblurred_img = scaled_img.filter(ImageFilter.GaussianBlur(20))
    return boxblurred_img_5,boxblurred_img_20,gaussianblurred_img

def scale_img(raw_img_path):
    with Image.open(raw_img_path) as img:
        transposed_img = img.rotate(180, expand=True)
        img_list = [transposed_img.rotate(angle, expand=True) for angle in [0, 45, 90, 135, 180, 225]]
        filtered_img_list = [filter_img(image) for image in img_list]
    return filtered_img_list




#function predicts images from test data for health status

def predict_image_state(image_path, model):
    try:
        if os.path.exists(image_path):
            img = Image.open(image_path)
            img = img.resize((128, 128))
            img = np.array(img) / 255.0
            img = np.expand_dims(img, axis=0)

            prediction = model.predict(img)

            if prediction[0][0] > 0.5:
                return "Infected"
            else:
                return "Healthy"
    except (UnidentifiedImageError, OSError):
        os.remove(image_path)

#images are resized to a 128 by 128 dimenion before used to make a model

def resize_image(input_image_path, output_image_path, target_size):
    try:
        image = Image.open(input_image_path)
        if image.size[0] == 0 or image.size[1] == 0:
            return
        if image.mode == 'RGBA':
            image = image.convert('RGB')
        resized_image = image.resize(target_size)
        resized_image.save(output_image_path)
    except (UnidentifiedImageError, OSError):
        os.remove(input_image_path)

#function creates a model using CNN from tf

def create_and_train_cnn(data_directory=r"C:\Users\pc\OneDrive\Documents\chicken\data_folder",target_size=(128, 128), epochs=20):
    img_list = []
    for subdir in os.listdir(data_directory):
        for item in os.listdir(os.path.join(data_directory,subdir)):
            if item.endswith(('.jpg', '.png', '.jpeg')):
                if item.endswith('.jpg'):
                    img_list = scale_img(os.path.join(os.path.join(data_directory, subdir), f'{item}'))
                    for identifier, img_set in enumerate(img_list):
                        for index, created_img in enumerate(img_set):
                            try:
                                created_img.save(os.path.join(os.path.join(data_directory, subdir), f'generated{identifier}_{index}.jpg'))
                            except OSError as e:
                                print(f"Error saving image: {e}")

                
                if item.endswith('.png'):
                    img_list = scale_img(os.path.join(os.path.join(data_directory, subdir), f'{item}'))
                    for identifier, img_set in enumerate(img_list):
                        for index, created_img in enumerate(img_set):
                            try:
                                created_img.save(os.path.join(os.path.join(data_directory, subdir), f'generated{identifier}_{index}.png'))
                            except OSError as e:
                                print(f"Error saving image: {e}")
                
                if item.endswith('.jpeg'):
                    img_list = scale_img(os.path.join(os.path.join(data_directory, subdir), f'{item}'))
                    for identifier, img_set in enumerate(img_list):
                        for index, created_img in enumerate(img_set):
                            try:
                                created_img.save(os.path.join(os.path.join(data_directory, subdir), f'generated{identifier}_{index}.jpeg'))
                            except OSError as e:
                                print(f"Error saving image: {e}")

                                
                file_path = os.path.join(os.path.join(data_directory, subdir),item)
                resize_image(file_path, file_path, target_size)

    for subdir in os.listdir(data_directory):
        for item in os.listdir(os.path.join(data_directory,subdir)):
            if item.endswith(('.jpg', '.png', '.jpeg')):
                file_path = os.path.join(os.path.join(data_directory, subdir),item)
                resize_image(file_path, file_path, target_size)
#use of the image generator
    train_data_gen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest',
        vertical_flip=True,
        brightness_range=[0.5, 1.5]
    )

    train_data = train_data_gen.flow_from_directory(
        data_directory,
        target_size=target_size,
        batch_size=32,
        class_mode='binary',
        subset="training"
    )

    validation_data_gen = ImageDataGenerator(rescale=1./255)

    validation_data = validation_data_gen.flow_from_directory(
        data_directory,
        target_size=target_size,
        batch_size=32,
        class_mode='binary',
        subset="validation"
    )

    model = keras.Sequential([
        layers.Conv2D(64, (3, 3), activation='relu', input_shape=(target_size[0], target_size[1], 3)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(256, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(1, activation='sigmoid')
    ])

    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)

    model.fit(
        train_data,
        epochs=epochs,
        validation_data=validation_data,
        steps_per_epoch=len(train_data),
        validation_steps=len(validation_data),
        callbacks=[lr_scheduler]
    )

    model.save(model_path)
    return model

#query to train a new model or continue with a precreated model

if input('Train Data? [y/n] ').lower() == 'y':
    trained_model = create_and_train_cnn()
else:
    trained_model = load_model(model_path)

#loop through each picture in test data and rename it to a 16 bit value

for item in os.listdir(test_data):
    image_path = os.path.join(test_data, item)
    os.rename(image_path,os.path.join(test_data, f'{secrets.token_urlsafe(16)}.jpg'))

def train_predict():
  if input('Train Data? [y/n] ').lower() == 'y':
      trained_model = create_and_train_cnn()
  else:
      trained_model = load_model(model_path)

  #loop through each picture in test data and rename it to a 16 bit value

  for item in os.listdir(test_data):
      image_path = os.path.join(test_data, item)
      os.rename(image_path,os.path.join(test_data, f'{secrets.token_urlsafe(16)}.jpg'))

  #loop through the test data to predict each status of the picture and rename the picture to its status

  for index,image in enumerate(os.listdir(test_data)):
      image_path1 = os.path.join(test_data, image)
      image_code = predict_image_state(image_path1, trained_model)
      if os.path.exists(image_path1):
          print(f'{image} status: {image_code}')
          new_path = os.path.join(test_data, f'{image_code}[{index}].jpg')
          os.rename(image_path1, new_path)

train_predict()