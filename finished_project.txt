
#import all dependencies

from tensorflow.keras.callbacks import ReduceLROnPlateau
import tensorflow
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os
from PIL import Image, UnidentifiedImageError
import numpy as np
import secrets

#include file paths

parent_path = os.getcwd()
parent_path1 = os.path.join(parent_path,'data_folder')
path = os.path.join(os.path.join(os.getcwd(), 'data_folder'),'healthy')
path1 = os.path.join(os.path.join(os.getcwd(), 'data_folder'),'infected')
model_path = os.path.join(os.getcwd(), 'chicken_model')
test_data = os.path.join(os.getcwd(), 'test_data')

#function predicts images from test data for health status

def predict_image_state(image_path, model):
    try:
        if os.path.exists(image_path):
            img = Image.open(image_path)
            img = img.resize((128, 128))
            img = np.array(img) / 255.0
            img = np.expand_dims(img, axis=0)

            prediction = model.predict(img)

            if prediction[0][0] > 0.5:
                return "Infected"
            else:
                return "Healthy"
    except (UnidentifiedImageError, OSError):
        os.remove(image_path)

#images are resized to a 128 by 128 dimenion before used to make a model

def resize_image(input_image_path, output_image_path, target_size):
    try:
        image = Image.open(input_image_path)
        if image.size[0] == 0 or image.size[1] == 0:
            return
        if image.mode == 'RGBA':
            image = image.convert('RGB')
        resized_image = image.resize(target_size)
        resized_image.save(output_image_path)
    except (UnidentifiedImageError, OSError):
        os.remove(input_image_path)

#function creates a model using CNN from tf

def create_and_train_cnn(data_directory=r"C:\Users\mmms\Desktop\chicken1\data_folder",target_size=(128, 128), epochs=20):
    for subdir in os.listdir(data_directory):
        for item in os.listdir(os.path.join(data_directory,subdir)):
            if item.endswith(('.jpg', '.png', '.jpeg')):
                file_path = os.path.join(os.path.join(data_directory, subdir),item)
                resize_image(file_path, file_path, target_size)

    train_data_gen = ImageDataGenerator(
        rescale=1./255,
        rotation_range=20,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.2,
        zoom_range=0.2,
        horizontal_flip=True,
        fill_mode='nearest',
        vertical_flip=True,
        brightness_range=[0.5, 1.5]
    )

    train_data = train_data_gen.flow_from_directory(
        data_directory,
        target_size=target_size,
        batch_size=32,
        class_mode='binary',
        subset="training"
    )

    validation_data_gen = ImageDataGenerator(rescale=1./255)

    validation_data = validation_data_gen.flow_from_directory(
        data_directory,
        target_size=target_size,
        batch_size=32,
        class_mode='binary',
        subset="validation"
    )

    model = keras.Sequential([
        layers.Conv2D(64, (3, 3), activation='relu', input_shape=(target_size[0], target_size[1], 3)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(256, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(128, activation='relu'),
        layers.Dropout(0.3),
        layers.Dense(1, activation='sigmoid')
    ])

    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7)

    model.fit(
        train_data,
        epochs=epochs,
        validation_data=validation_data,
        steps_per_epoch=len(train_data),
        validation_steps=len(validation_data),
        callbacks=[lr_scheduler]
    )

    model.save(model_path)
    return model

#query to train a new model or continue with a precreated model

if input('Train Data? [y/n] ').lower() == 'y':
    trained_model = create_and_train_cnn()
else:
    trained_model = load_model(model_path)

#loop through each picture in test data and rename it to a 16 bit value

for item in os.listdir(test_data):
    image_path = os.path.join(test_data, item)
    os.rename(image_path,os.path.join(test_data, f'{secrets.token_urlsafe(16)}.jpg'))

loop through the test data to predict each status of the picture and rename the picture to its status

for index,image in enumerate(os.listdir(test_data)):
    image_path1 = os.path.join(test_data, image)
    image_code = predict_image_state(image_path1, trained_model)
    if os.path.exists(image_path1):
        print(f'{image} status: {image_code}')
        new_path = os.path.join(test_data, f'{image_code}[{index}].jpg')
        os.rename(image_path1, new_path)